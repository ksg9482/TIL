# 아파치 카프카
### 카프카 이전
데이터를 전송하는 소스 에플리케이션과 데이터를 받는 타겟 애플리케이션이 있다.
처음에는 간단하게 단방향 데이터 통신을 수행 했다. 하지만 시간이 지나 소스 애플리케이션과 타켓 애플리케이션이 많아지면서 데이터를 조성하는 라인이 매우 복잡해졌다.
이런 라인이 많아질수록 배포와 장애에 대응하기 어렵다. 그리고 데이터를 전송할 때 프로토콜 파편화가 심각해졌다.

아파티 카프카는 이런 문제를 해소하기 위해 만들어졌다. 카프카의 주 목적은 소스 어플리케이션과 타겟 어플리케이션의 커플링을 약하게 하기 위해 나왔다.
소스 -> 카프카 (온갖 로그)
카프카 -> 타겟 (로그 적재/처리)

### 토픽
카프카는 토픽 단위로 데이터를 입력하고, 이 입력하는게 프로듀서 가져오는게 컨슈머이다.

카프카에 들어가는 데이터 종류는 거의 무제한이다. 이 데이터가 들어가는 공간이 토픽. 일반적인 AMQP와는 다르게 동작한다.
토픽은 DB의 테이블 또는 파일시스템의 폴더와 유사한 성질을 가진다. 
* 하나의 토픽을 여러개의 파티션으로 구성될 수 있다.
* 파티션 시작은 0번 부터.
* 하나의 파티션은 큐와 같이 데이터가 파티션 끝에서부터 쌓이게 됨.
* 컨슈머는 파티션의 가장 오래된 순서(큐의 맨 위)부터 가져간다.
* 데이터가 들어오지 않으면 컨슈머는 데이터를 대기한다.
  * 중요한점. 데이터는 삭제되지 않고 내부에 유지된다.
  * 다른 컨슈머가 붙으면 다시 파티션의 0번 부터 데이터를 가져간다.
  * 단 컨슈머 그룹이 달라야하고 auto.offset.reset이 earliest여야 한다.

파티션이 2개 이상인 경우?
만약 신규 데이터를 입력해야 한다면
* 키가 null, 기본 파티셔너 사용할 경우 -> 라운드 로빈(Round robin)으로 할당
* 키가 있고, 기본 파티셔너 사용할 경우 -> 키의 해시 값 구해서 특정 파티션에 할당

파티션을 늘리는 것은 신중해야 한다. 파티션을 늘리는 것은 가능하지만 다시 줄일 수 없다.
그럼에도 파티션을 늘리는 이유는 컨슈머를 늘려서 데이터 처리를 분산시킬 수 있기 때문이다.

파티션의 데이터(레코드)가 삭제되는 타이밍은 옵션마다 다름. 레코드가 저장되는 기간, 용량을 지정할 수 있다.

### 카프카의 중요 3요소
브로커(Broker), 복제, ISR(In-Sync-Replication)
특히 복제가 중요하다. 클러스터에서 서버 장애가 생길 때 가용성을 보장하는 가장 좋은 방법이 복제이기 때문.

#### 브로커
브로커는 카프카가 설치되어 있는 서버 단위를 말한다. 보통 3개 이상의 브로커로 구성하여 사용하는 것을 권장.
만약 파티션이 1개, 토픽이 1개, 브로커가 3개라면 1대에 해당 토픽의 정보(데이터)가 저장된다. 
* partition: 1, replication(복제): 1 -> 파티션이 1개 존재
* partition: 1, replication(복제): 3 -> 파티션 원본 1개, 복제 2개 존재(총 3개, 브로커도 3개 - 브로커 개수에 영향 받는다)

원본 파티션을 Leader partition이라 부르고, 나머지 복제 파티션을 Follower partition이라고 부른다.
리더, 팔로워 파티션을 합쳐서 ISR이라고 한다. 리더 파티션 브로커가 사용 불가능하게 되어도 팔로워 브로커가 리더 역할을 승계하게 된다.

#### ISR
리더 파티션과 팔로워 파티션의 차이점
* 프로듀서가 데이터를 전송할때 데이터를 전달받는 주체가 리더 파티션
* 프로듀서의 ack옵션: 0,1,all
  * 0: 리더 파티션에 데이터 전송 + 응답값 안 받음. 속도는 빠르나 브로커 정상 여부 모름. 데이터 유실 가능성 있음.
  * 1: 리더 파티션에 데이터 전송 + 응답값 받음. 응답값은 받지만 나머지 파티션에 복제되었는지는 모름. 리더 파티션이 데이터를 받자마자 장애가 난다면 데이터 유실 가능성 있음.
  * all: 리더 파티션에 데이터 전송 + 팔로워 데이터 복제 여부까지 확인. 데이터 유실 가능성 없음. 하지만 속도가 현저히 느림.

replication이 많을 수록 좋은가? 

메모리 사용량이 많아짐. 카프카에 들어오는 데이터량과 데이터 유지시간을 잘 고려해서 구성하는게 좋다.

#### 파티셔너
파티셔너는 프로듀서의 중요 개념중 하나이다. 프로듀서가 데이터를 보내면 파티셔너를 통해 브로커로 데이터가 전송된다.
어떤 파티션에 넣을지 결정하는 것이 파티셔너이고, 레코드에 포함된 메시지 키 또는 메시지 값에 따라서 파티션의 위치가 정해진다.
특별히 설정하지 않는다면 UniformStickyPartitioner로 설정된다. 이 파티셔너는 메시지 키가 있을 때와 없을 때 서로 다르게 동작한다.
* 키가 있을 경우: 키를 가진 레코드는 파티셔너에 의해 특정한 해쉬값이 생성된다. 해쉬값에 의해 어떤 파티션에 들어갈지 정해지게 되고, 동일한 해쉬값은 동일한 파티션에 들어가는 것을 보장한다. 이는 순서를 지켜서 데이터를 처리할 수 있다는 장점이 있다. 예를 들어 시계열 데이터. 파티션 내부에서는 큐처럼 동작하기 때문에 가능한 것,
* 키가 없는 경우: 키가 없으면 라운드 로빈으로 파티션에 들어가게 된다. 전통적인 방식과 다른점은 프로듀서에서 배치로 모을 수 있는 최대한의 데이터를 모아서 파이션에 데이터를 보낸다. 배치 단위로 라운드 로빈으로 넣는 것.

커스텀 파티셔너도 만들 수 있다. 카프카는 파티셔너 인터페이스를 제공한다. 
커스텀 파티셔너 사용 예시? VIP 고객을 우선 처리하는 방식도 가능. 10개 파티션이 있다면 VIP용 8개, 일반 고객용 2개를 구성해서 데이터 처리량을 VIP에게 몰아주는 형태로 개발 할 수 있다.
